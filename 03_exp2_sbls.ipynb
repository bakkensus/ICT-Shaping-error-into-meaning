{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d8319b-9b8d-428a-8bf5-80d36d7984d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 1 (Complete Experiment Code) ===\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models import resnet18\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ==========================================\n",
    "# 1. KONFIGURASJON & OPPSETT\n",
    "# ==========================================\n",
    "EXPERIMENT_NAME = \"03_exp2_sbls\"\n",
    "DATA_DIR = Path(\"./data\")\n",
    "BASE_ARTIFACTS_DIR = Path(f\"./artifacts/{EXPERIMENT_NAME}\")\n",
    "CKPT_DIR = Path(\"./checkpoints\")\n",
    "\n",
    "# Opprett mapper\n",
    "BASE_ARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CKPT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Hyperparametere\n",
    "RUNS = [50, 300]        # Vi kjører både kort (50) og lang (300) trening\n",
    "BATCH_SIZE = 128\n",
    "LR = 1e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "SEED = 42\n",
    "NUM_WORKERS = 2\n",
    "USE_AMP = True\n",
    "\n",
    "# SBLS Spesifikke parametere\n",
    "ALPHA = 0.2             # Smoothing mass (Hvor mye sannsynlighet vi tar fra true class)\n",
    "NUM_CLASSES = 10\n",
    "CIFAR10_CLASSES = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
    "\n",
    "print(f\"Konfigurasjon satt for {EXPERIMENT_NAME}.\")\n",
    "print(f\"Artefakter lagres til: {BASE_ARTIFACTS_DIR}\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. REPRODUSERBARHET\n",
    "# ==========================================\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "set_seed(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Kjører på: {device}\")\n",
    "\n",
    "# ==========================================\n",
    "# 3. DATA LOADING\n",
    "# ==========================================\n",
    "train_tf = T.Compose([\n",
    "    T.RandomCrop(32, padding=4),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "eval_tf = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "train_ds_aug = torchvision.datasets.CIFAR10(root=DATA_DIR, train=True, download=True, transform=train_tf)\n",
    "test_ds = torchvision.datasets.CIFAR10(root=DATA_DIR, train=False, download=True, transform=eval_tf)\n",
    "\n",
    "train_loader = DataLoader(train_ds_aug, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "# ==========================================\n",
    "# 4. MODELL DEFINISJON\n",
    "# ==========================================\n",
    "def make_cifar_resnet18(num_classes=10):\n",
    "    m = resnet18(weights=None)\n",
    "    m.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    m.maxpool = nn.Identity()\n",
    "    m.fc = nn.Linear(m.fc.in_features, num_classes)\n",
    "    return m\n",
    "\n",
    "# ==========================================\n",
    "# 5. SBLS LOGIKK (Likhetsmatrise & Targets)\n",
    "# ==========================================\n",
    "def build_similarity_matrix_cifar10():\n",
    "    \"\"\"\n",
    "    Bygger en manuell likhetsmatrise basert på superklasser i CIFAR-10.\n",
    "    Animals: bird, cat, deer, dog, frog, horse (indices 2,3,4,5,6,7)\n",
    "    Vehicles: airplane, automobile, ship, truck (indices 0,1,8,9)\n",
    "    \"\"\"\n",
    "    C = len(CIFAR10_CLASSES)\n",
    "    S = torch.zeros(C, C)\n",
    "    \n",
    "    animals = {2, 3, 4, 5, 6, 7}\n",
    "    vehicles = {0, 1, 8, 9}\n",
    "    \n",
    "    for i in range(C):\n",
    "        for j in range(C):\n",
    "            if i == j:\n",
    "                S[i, j] = 0.0 # Ingen selv-likhet her (håndteres av alpha i target-generering)\n",
    "            else:\n",
    "                if (i in animals and j in animals) or (i in vehicles and j in vehicles):\n",
    "                    S[i, j] = 1.0 # \"Lik\"\n",
    "                else:\n",
    "                    S[i, j] = 0.0 # \"Ulik\"\n",
    "                    \n",
    "    # Normaliser rader slik at summen av naboer blir 1.0\n",
    "    row_sums = S.sum(dim=1, keepdim=True).clamp_min(1e-8)\n",
    "    S = S / row_sums\n",
    "    return S\n",
    "\n",
    "# Opprett matrisen og legg på device\n",
    "S_MAT = build_similarity_matrix_cifar10().to(device)\n",
    "\n",
    "def make_soft_targets(y, S, alpha=0.2, num_classes=10):\n",
    "    \"\"\"\n",
    "    Genererer soft targets on-the-fly for en batch.\n",
    "    y: (B,) labels\n",
    "    S: (C, C) similarity matrix\n",
    "    alpha: Hvor mye masse som skal fordeles til naboer.\n",
    "    \"\"\"\n",
    "    B = y.shape[0]\n",
    "    # Start med standard one-hot\n",
    "    T = torch.zeros(B, num_classes, device=y.device)\n",
    "    T.scatter_(1, y.view(-1, 1), 1.0)\n",
    "    \n",
    "    if alpha <= 0:\n",
    "        return T\n",
    "    \n",
    "    # Reduser sannsynligheten for sann klasse\n",
    "    T = T * (1.0 - alpha)\n",
    "    \n",
    "    # Hent nabo-fordeling fra S-matrisen\n",
    "    # S[y] velger radene som tilsvarer labelene i batchen -> (B, C)\n",
    "    neighbor_dist = S[y]\n",
    "    \n",
    "    # Sjekk om noen klasser ikke har naboer (row sums ~ 0) -> fallback til uniform distribution\n",
    "    row_sums = neighbor_dist.sum(dim=1, keepdim=True)\n",
    "    fallback = (row_sums < 1e-7).float()\n",
    "    \n",
    "    if fallback.any():\n",
    "        # Fordel alpha uniformt over alle ANDRE klasser enn seg selv\n",
    "        uniform = torch.ones_like(neighbor_dist) / (num_classes - 1)\n",
    "        uniform.scatter_(1, y.view(-1, 1), 0.0)\n",
    "        neighbor_dist = torch.where(fallback.bool(), uniform, neighbor_dist)\n",
    "        \n",
    "    # Legg til alpha-massen fordelt på naboer\n",
    "    T = T + alpha * neighbor_dist\n",
    "    return T\n",
    "\n",
    "def soft_ce_loss(logits, soft_targets):\n",
    "    \"\"\"Cross Entropy med soft targets (probabilities).\"\"\"\n",
    "    log_probs = F.log_softmax(logits, dim=1)\n",
    "    return -(soft_targets * log_probs).sum(dim=1).mean()\n",
    "\n",
    "# ==========================================\n",
    "# 6. VISUALISERING AV TARGETS\n",
    "# ==========================================\n",
    "# Vi visualiserer hvordan target-distribusjonen ser ut for hver klasse\n",
    "# Dette tilsvarer \"Target Distribution Heatmap\" kravet.\n",
    "print(\"Genererer Heatmap for SBLS Targets...\")\n",
    "\n",
    "# Lag en dummy batch med en av hver klasse for å visualisere matrisen\n",
    "dummy_y = torch.arange(NUM_CLASSES, device=device)\n",
    "dummy_targets = make_soft_targets(dummy_y, S_MAT, alpha=ALPHA, num_classes=NUM_CLASSES)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(\n",
    "    dummy_targets.cpu().numpy(),\n",
    "    xticklabels=CIFAR10_CLASSES,\n",
    "    yticklabels=CIFAR10_CLASSES,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cmap=\"viridis\",\n",
    "    cbar_kws={'label': f'Target Probability (Alpha={ALPHA})'}\n",
    ")\n",
    "plt.title(f\"Experiment 2: SBLS Target Distribution (Manual Groups)\")\n",
    "plt.xlabel(\"Target Class\")\n",
    "plt.ylabel(\"Source Class\")\n",
    "plt.tight_layout()\n",
    "\n",
    "heatmap_path = BASE_ARTIFACTS_DIR / \"target_distribution_heatmap.png\"\n",
    "plt.savefig(heatmap_path)\n",
    "print(f\"Heatmap lagret til: {heatmap_path}\")\n",
    "plt.show()\n",
    "\n",
    "# Lagre selve matrisen også\n",
    "torch.save(dummy_targets.cpu(), BASE_ARTIFACTS_DIR / \"sbls_target_matrix.pt\")\n",
    "\n",
    "# ==========================================\n",
    "# 7. TRENINGS- OG EVALUERINGSFUNKSJONER\n",
    "# ==========================================\n",
    "def train_one_epoch(model, loader, optimizer, scaler):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        \n",
    "        with torch.autocast(device_type=\"cuda\" if device.type == \"cuda\" else \"cpu\", enabled=USE_AMP):\n",
    "            logits = model(x)\n",
    "            # Generer targets dynamisk basert på SBLS logikk\n",
    "            soft_targets = make_soft_targets(y, S_MAT, alpha=ALPHA, num_classes=NUM_CLASSES)\n",
    "            loss = soft_ce_loss(logits, soft_targets)\n",
    "            \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        total_loss += loss.item() * x.size(0)\n",
    "        correct += (logits.argmax(dim=1) == y).sum().item()\n",
    "        total += x.size(0)\n",
    "        \n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    correct_top1 = 0\n",
    "    correct_top2 = 0\n",
    "    ranks_sum = 0.0\n",
    "    total = 0\n",
    "    \n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "        logits = model(x)\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        \n",
    "        # Top-k metrics\n",
    "        top2 = probs.topk(2, dim=1).indices\n",
    "        pred_top1 = top2[:, 0]\n",
    "        correct_top1 += (pred_top1 == y).sum().item()\n",
    "        correct_top2 += ((top2[:, 0] == y) | (top2[:, 1] == y)).sum().item()\n",
    "        \n",
    "        # Mean Rank\n",
    "        sorted_indices = logits.argsort(dim=1, descending=True)\n",
    "        ranks = (sorted_indices == y.view(-1, 1)).nonzero()[:, 1] + 1\n",
    "        ranks_sum += ranks.float().sum().item()\n",
    "        \n",
    "        total += x.size(0)\n",
    "        \n",
    "    return {\n",
    "        \"acc1\": correct_top1 / total,\n",
    "        \"acc2\": correct_top2 / total,\n",
    "        \"mean_rank\": ranks_sum / total\n",
    "    }\n",
    "\n",
    "# ==========================================\n",
    "# 8. HOVEDLØKKE (RUNNER)\n",
    "# ==========================================\n",
    "for max_epochs in RUNS:\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"  STARTER KJØRING: {max_epochs} EPOKER\")\n",
    "    print(f\"{'='*40}\")\n",
    "    \n",
    "    # Initier for denne kjøringen\n",
    "    run_dir = BASE_ARTIFACTS_DIR / f\"run_{max_epochs}ep\"\n",
    "    run_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    model = make_cifar_resnet18(NUM_CLASSES).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=USE_AMP)\n",
    "    \n",
    "    best_acc = 0.0\n",
    "    history = {\"train_loss\": [], \"train_acc\": [], \"test_acc1\": [], \"test_acc2\": [], \"mean_rank\": []}\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(1, max_epochs + 1):\n",
    "        t_loss, t_acc = train_one_epoch(model, train_loader, optimizer, scaler)\n",
    "        metrics = evaluate(model, test_loader)\n",
    "        \n",
    "        history[\"train_loss\"].append(t_loss)\n",
    "        history[\"train_acc\"].append(t_acc)\n",
    "        history[\"test_acc1\"].append(metrics[\"acc1\"])\n",
    "        history[\"test_acc2\"].append(metrics[\"acc2\"])\n",
    "        history[\"mean_rank\"].append(metrics[\"mean_rank\"])\n",
    "        \n",
    "        if metrics[\"acc1\"] > best_acc:\n",
    "            best_acc = metrics[\"acc1\"]\n",
    "            torch.save(model.state_dict(), CKPT_DIR / f\"{EXPERIMENT_NAME}_{max_epochs}ep_best.pth\")\n",
    "            \n",
    "        if epoch % 10 == 0 or epoch == 1:\n",
    "            elapsed = time.time() - start_time\n",
    "            print(f\"Ep {epoch:03d} | Loss: {t_loss:.4f} | TrAcc: {t_acc:.3f} | \"\n",
    "                  f\"TeAcc1: {metrics['acc1']:.3f} | Rank: {metrics['mean_rank']:.2f} | T: {elapsed:.0f}s\")\n",
    "            \n",
    "    # Lagre resultater for denne kjøringen\n",
    "    res_file = run_dir / \"results.json\"\n",
    "    with open(res_file, \"w\") as f:\n",
    "        json.dump({\n",
    "            \"config\": {\n",
    "                \"epochs\": max_epochs,\n",
    "                \"alpha\": ALPHA,\n",
    "                \"lr\": LR\n",
    "            },\n",
    "            \"best_acc\": best_acc,\n",
    "            \"history\": history\n",
    "        }, f, indent=2)\n",
    "        \n",
    "    # Lagre plott av trening\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(history[\"train_loss\"], label=\"Train Loss\")\n",
    "    plt.title(f\"Training Loss ({max_epochs} epochs) - SBLS\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(run_dir / \"loss_curve.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Ferdig med {max_epochs} epoker. Beste Acc: {best_acc:.4f}. Data lagret i {run_dir}\")\n",
    "\n",
    "print(f\"\\nAlle kjøringer fullført for {EXPERIMENT_NAME}!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
