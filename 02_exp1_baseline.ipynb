{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7380426-c1b3-4bd6-9760-4d344d2e3151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 1 (Imports) ===\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models import resnet18\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# === CELL 2 (Configuration) ===\n",
    "# --- Konfigurasjon ---\n",
    "EXPERIMENT_NAME = \"02_exp1_baseline\"\n",
    "DATA_DIR = Path(\"./data\")\n",
    "ARTIFACTS_DIR = Path(f\"./artifacts/{EXPERIMENT_NAME}\")\n",
    "CKPT_DIR = Path(\"./checkpoints\")\n",
    "\n",
    "# Opprett mapper\n",
    "ARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CKPT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Hyperparametere\n",
    "MAIN_EPOCHS = 300        # Kjører 300 (dekker også behovet for 50)\n",
    "BATCH_SIZE = 128\n",
    "LR = 1e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "SEED = 42\n",
    "NUM_WORKERS = 2\n",
    "USE_AMP = True\n",
    "\n",
    "# Data & Klasser\n",
    "NUM_CLASSES = 10\n",
    "CIFAR10_CLASSES = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
    "\n",
    "print(f\"Konfigurasjon satt for {EXPERIMENT_NAME}.\")\n",
    "print(f\"Artefakter lagres til: {ARTIFACTS_DIR}\")\n",
    "\n",
    "# === CELL 3 (Reproducibility) ===\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "set_seed(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Kjører på: {device}\")\n",
    "\n",
    "# === CELL 4 (Data Loading) ===\n",
    "# Samme transformasjoner som i det gamle repoet (og probe setup)\n",
    "train_tf = T.Compose([\n",
    "    T.RandomCrop(32, padding=4),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "eval_tf = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# Datasets\n",
    "train_ds_aug = torchvision.datasets.CIFAR10(root=DATA_DIR, train=True, download=True, transform=train_tf)\n",
    "test_ds = torchvision.datasets.CIFAR10(root=DATA_DIR, train=False, download=True, transform=eval_tf)\n",
    "\n",
    "# Loaders\n",
    "train_loader = DataLoader(train_ds_aug, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "print(f\"Data lastet. Train size: {len(train_ds_aug)}, Test size: {len(test_ds)}\")\n",
    "\n",
    "# === CELL 5 (Model Definition) ===\n",
    "def make_cifar_resnet18(num_classes=10):\n",
    "    \"\"\"\n",
    "    Standard ResNet18 tilpasset CIFAR-10.\n",
    "    Identisk arkitektur som brukt i Probe og gamle eksperimenter.\n",
    "    \"\"\"\n",
    "    m = resnet18(weights=None)\n",
    "    m.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    m.maxpool = nn.Identity()\n",
    "    m.fc = nn.Linear(m.fc.in_features, num_classes)\n",
    "    return m\n",
    "\n",
    "model = make_cifar_resnet18(NUM_CLASSES).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=USE_AMP)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# === CELL 6 (Evaluation Utilities) ===\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader):\n",
    "    \"\"\"\n",
    "    Evaluerer modellen og returnerer:\n",
    "    - Top-1 Accuracy\n",
    "    - Top-2 Accuracy\n",
    "    - Mean Rank (Gjennomsnittlig rangering av sann klasse)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct_top1 = 0\n",
    "    correct_top2 = 0\n",
    "    ranks_sum = 0.0\n",
    "    \n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "        logits = model(x)\n",
    "        \n",
    "        # Sannsynligheter\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        \n",
    "        # Top-k\n",
    "        top2 = probs.topk(2, dim=1).indices\n",
    "        pred_top1 = top2[:, 0]\n",
    "        \n",
    "        correct_top1 += (pred_top1 == y).sum().item()\n",
    "        correct_top2 += ((top2[:, 0] == y) | (top2[:, 1] == y)).sum().item()\n",
    "        \n",
    "        # Mean Rank calculation\n",
    "        # argsort descending gir indeksene sortert etter confidence.\n",
    "        # Vi finner hvor sann klasse (y) befinner seg i denne sorteringen.\n",
    "        # .nonzero()[:, 1] gir kolonne-indeksen (rangeringen, 0-indeksert)\n",
    "        sorted_indices = logits.argsort(dim=1, descending=True)\n",
    "        ranks = (sorted_indices == y.view(-1, 1)).nonzero()[:, 1] + 1\n",
    "        ranks_sum += ranks.float().sum().item()\n",
    "        \n",
    "        total += x.size(0)\n",
    "        \n",
    "    return {\n",
    "        \"acc1\": correct_top1 / total,\n",
    "        \"acc2\": correct_top2 / total,\n",
    "        \"mean_rank\": ranks_sum / total\n",
    "    }\n",
    "\n",
    "# === CELL 7 (Training Loop) ===\n",
    "def train_one_epoch(model, loader, optimizer, scaler):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        \n",
    "        with torch.autocast(device_type=\"cuda\" if device.type == \"cuda\" else \"cpu\", enabled=USE_AMP):\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        total_loss += loss.item() * x.size(0)\n",
    "        correct += (logits.argmax(dim=1) == y).sum().item()\n",
    "        total += x.size(0)\n",
    "        \n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "# === CELL 8 (Run Experiment) ===\n",
    "print(f\"Starter Eksperiment 1: Baseline (Cross-Entropy)\")\n",
    "print(f\"Total Epoker: {MAIN_EPOCHS}\")\n",
    "\n",
    "best_acc = 0.0\n",
    "history = {\"train_loss\": [], \"train_acc\": [], \"test_acc1\": [], \"test_acc2\": [], \"mean_rank\": []}\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(1, MAIN_EPOCHS + 1):\n",
    "    t_loss, t_acc = train_one_epoch(model, train_loader, optimizer, scaler)\n",
    "    val_metrics = evaluate(model, test_loader)\n",
    "    \n",
    "    # Lagre historikk\n",
    "    history[\"train_loss\"].append(t_loss)\n",
    "    history[\"train_acc\"].append(t_acc)\n",
    "    history[\"test_acc1\"].append(val_metrics[\"acc1\"])\n",
    "    history[\"test_acc2\"].append(val_metrics[\"acc2\"])\n",
    "    history[\"mean_rank\"].append(val_metrics[\"mean_rank\"])\n",
    "    \n",
    "    # Lagre beste modell\n",
    "    if val_metrics[\"acc1\"] > best_acc:\n",
    "        best_acc = val_metrics[\"acc1\"]\n",
    "        torch.save(model.state_dict(), CKPT_DIR / f\"{EXPERIMENT_NAME}_best.pth\")\n",
    "    \n",
    "    # Lagre sjekkpunkt ved 50 epoker (for sammenligning)\n",
    "    if epoch == 50:\n",
    "        torch.save(model.state_dict(), CKPT_DIR / f\"{EXPERIMENT_NAME}_epoch50.pth\")\n",
    "        print(f\"   -> Sjekkpunkt lagret ved epoke 50.\")\n",
    "\n",
    "    # Logging\n",
    "    if epoch % 10 == 0 or epoch == 1:\n",
    "        dt = time.time() - start_time\n",
    "        print(f\"Ep {epoch:03d} | Loss: {t_loss:.4f} | TrAcc: {t_acc:.3f} | \"\n",
    "              f\"TeAcc1: {val_metrics['acc1']:.3f} | Rank: {val_metrics['mean_rank']:.2f} | T: {dt:.0f}s\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\nFerdig! Beste Test Acc: {best_acc:.4f}. Tid: {total_time/60:.1f} min.\")\n",
    "\n",
    "# === CELL 9 (Save Results & Artifacts) ===\n",
    "# 1. Lagre treningshistorikk\n",
    "results_file = ARTIFACTS_DIR / \"results.json\"\n",
    "with open(results_file, \"w\") as f:\n",
    "    json.dump({\n",
    "        \"config\": {\n",
    "            \"epochs\": MAIN_EPOCHS,\n",
    "            \"lr\": LR,\n",
    "            \"batch_size\": BATCH_SIZE,\n",
    "            \"seed\": SEED\n",
    "        },\n",
    "        \"best_acc\": best_acc,\n",
    "        \"history\": history\n",
    "    }, f, indent=2)\n",
    "print(f\"Resultater lagret til {results_file}\")\n",
    "\n",
    "# 2. Generer Target Distribution Heatmap\n",
    "# Siden dette er Baseline (Cross Entropy), er målet One-Hot.\n",
    "# Det betyr at 'Airplane' skal være 100% 'Airplane' og 0% alt annet.\n",
    "# Target Distribution er dermed en Identitetsmatrise.\n",
    "\n",
    "print(\"Genererer Heatmap for Target Distribution...\")\n",
    "target_matrix = torch.eye(NUM_CLASSES).numpy()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(\n",
    "    target_matrix,\n",
    "    xticklabels=CIFAR10_CLASSES,\n",
    "    yticklabels=CIFAR10_CLASSES,\n",
    "    annot=True,\n",
    "    fmt=\".1f\", # Vis 1.0 eller 0.0\n",
    "    cmap=\"Blues\",\n",
    "    cbar_kws={'label': 'Target Probability (One-Hot)'}\n",
    ")\n",
    "plt.title(f\"Baseline Targets (One-Hot / Hard Labels)\")\n",
    "plt.xlabel(\"Target Class\")\n",
    "plt.ylabel(\"Source Class\")\n",
    "plt.tight_layout()\n",
    "\n",
    "heatmap_path = ARTIFACTS_DIR / \"target_distribution_heatmap.png\"\n",
    "plt.savefig(heatmap_path)\n",
    "print(f\"Heatmap lagret til: {heatmap_path}\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
