{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef4e938-fa46-4df8-a01d-de3a5f92a8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet18\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ==========================================\n",
    "# 1. KONFIGURASJON\n",
    "# ==========================================\n",
    "DATA_DIR = Path(\"./data\")\n",
    "ARTIFACTS_DIR = Path(\"./artifacts/analysis\")\n",
    "CKPT_DIR = Path(\"./checkpoints\")\n",
    "JSON_PATH = Path(\"human_similarity_ranking.json\")\n",
    "\n",
    "ARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 128\n",
    "NUM_CLASSES = 10\n",
    "CIFAR10_CLASSES = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
    "\n",
    "# Liste over ALLE modeller (50ep og 300ep)\n",
    "# N√∏klene er formatert som \"Navn - Epoker\" for enklere parsing senere\n",
    "POSSIBLE_MODELS = {\n",
    "    \"Probe (Teacher)\":                    \"probe_best.pth\",\n",
    "    \n",
    "    \"Baseline (Exp 1) - 50ep\":            \"02_exp1_baseline_epoch50.pth\",\n",
    "    \"Baseline (Exp 1) - 300ep\":           \"02_exp1_baseline_best.pth\",\n",
    "    \n",
    "    \"SBLS (Exp 2) - 50ep\":                \"03_exp2_sbls_50ep_best.pth\",\n",
    "    \"SBLS (Exp 2) - 300ep\":               \"03_exp2_sbls_300ep_best.pth\",\n",
    "    \n",
    "    \"Static KL (Exp 3a) - 50ep\":          \"04_exp3a_static_probs_50ep_best.pth\",\n",
    "    \"Static KL (Exp 3a) - 300ep\":         \"04_exp3a_static_probs_300ep_best.pth\",\n",
    "    \n",
    "    \"Static WMSE (Exp 3b) - 50ep\":        \"05_exp3b_static_logits_50ep_best.pth\",\n",
    "    \"Static WMSE (Exp 3b) - 300ep\":       \"05_exp3b_static_logits_300ep_best.pth\",\n",
    "    \n",
    "    \"Dynamic Basic (Exp 4a) - 50ep\":      \"06_exp4a_dynamic_basic_50ep_best.pth\",\n",
    "    \"Dynamic Basic (Exp 4a) - 300ep\":     \"06_exp4a_dynamic_basic_300ep_best.pth\",\n",
    "    \n",
    "    \"Dynamic Boost (Exp 4b) - 50ep\":      \"07_exp4b_dynamic_boost_50ep_best.pth\",\n",
    "    \"Dynamic Boost (Exp 4b) - 300ep\":     \"07_exp4b_dynamic_boost_300ep_best.pth\",\n",
    "    \n",
    "    \"Capped 0.8 (Exp 5a) - 50ep\":         \"08_exp5a_capped_run_50ep_cap0.8_best.pth\",\n",
    "    \"Capped 0.8 (Exp 5a) - 300ep\":        \"08_exp5a_capped_run_300ep_cap0.8_best.pth\",\n",
    "    \n",
    "    \"Swap+Capped 0.8 (Exp 5b) - 50ep\":    \"09_exp5b_capped_swap_run_50ep_cap0.8_best.pth\",\n",
    "    \"Swap+Capped 0.8 (Exp 5b) - 300ep\":   \"09_exp5b_capped_swap_run_300ep_cap0.8_best.pth\"\n",
    "}\n",
    "\n",
    "# ==========================================\n",
    "# 2. DATA & MODELL DEFINISJONER\n",
    "# ==========================================\n",
    "def make_cifar_resnet18(num_classes=10):\n",
    "    m = resnet18(weights=None)\n",
    "    m.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    m.maxpool = nn.Identity()\n",
    "    m.fc = nn.Linear(m.fc.in_features, num_classes)\n",
    "    return m\n",
    "\n",
    "def get_test_loader():\n",
    "    test_tf = T.Compose([\n",
    "        T.ToTensor(),\n",
    "        T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "    test_ds = torchvision.datasets.CIFAR10(root=DATA_DIR, train=False, download=True, transform=test_tf)\n",
    "    # Shuffle=False er KRITISK for \"Fair Comparison\" (indeks-matching)\n",
    "    return DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "# ==========================================\n",
    "# 3. HUMAN SIMILARITY MATRIX LOADER\n",
    "# ==========================================\n",
    "def load_human_similarity_matrix(json_path):\n",
    "    if not json_path.exists():\n",
    "        print(f\"‚ö†Ô∏è  ADVARSEL: Fant ikke {json_path}. Lager dummy-matrise (0 poeng).\")\n",
    "        return torch.zeros((NUM_CLASSES, NUM_CLASSES), device=DEVICE)\n",
    "    \n",
    "    with open(json_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    wins_data = data.get(\"wins\", {})\n",
    "    score_matrix = torch.zeros((NUM_CLASSES, NUM_CLASSES), device=DEVICE)\n",
    "    \n",
    "    for true_idx, true_name in enumerate(CIFAR10_CLASSES):\n",
    "        if true_name not in wins_data: continue\n",
    "        for pred_idx, pred_name in enumerate(CIFAR10_CLASSES):\n",
    "            if true_idx == pred_idx: continue # Ignorer diagonalen (korrekt svar)\n",
    "            \n",
    "            # Hent poeng\n",
    "            points = wins_data[true_name].get(pred_name, 0)\n",
    "            score_matrix[true_idx, pred_idx] = points\n",
    "\n",
    "    print(f\"Human Similarity Matrix lastet fra {json_path}.\")\n",
    "    return score_matrix\n",
    "\n",
    "# ==========================================\n",
    "# 4. PREDICTION COLLECTOR\n",
    "# ==========================================\n",
    "def collect_predictions(models_dict, loader):\n",
    "    all_preds = {}\n",
    "    targets = []\n",
    "    \n",
    "    # Hent targets f√∏rst\n",
    "    print(\"Laster testdata (fasit)...\")\n",
    "    for _, y in loader:\n",
    "        targets.append(y.to(DEVICE))\n",
    "    targets = torch.cat(targets)\n",
    "    \n",
    "    # Iterer over modeller\n",
    "    print(\"\\nStarter inferens p√• alle modeller...\")\n",
    "    for name, filename in tqdm(models_dict.items(), desc=\"Modeller\"):\n",
    "        ckpt_path = CKPT_DIR / filename\n",
    "        \n",
    "        if not ckpt_path.exists():\n",
    "            # Fallback hvis stien er litt annerledes eller bruker la inn full path\n",
    "            if Path(filename).exists():\n",
    "                ckpt_path = Path(filename)\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è  Hopper over {name}: Fant ikke {ckpt_path}\")\n",
    "                continue\n",
    "        \n",
    "        # Last modell\n",
    "        model = make_cifar_resnet18(NUM_CLASSES).to(DEVICE)\n",
    "        try:\n",
    "            model.load_state_dict(torch.load(ckpt_path, map_location=DEVICE))\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Kunne ikke laste {name}: {e}\")\n",
    "            continue\n",
    "            \n",
    "        model.eval()\n",
    "        preds_list = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for x, _ in loader:\n",
    "                x = x.to(DEVICE)\n",
    "                logits = model(x)\n",
    "                preds_list.append(logits.argmax(dim=1))\n",
    "        \n",
    "        all_preds[name] = torch.cat(preds_list)\n",
    "        \n",
    "    return all_preds, targets\n",
    "\n",
    "# ==========================================\n",
    "# 5. ANALYSE-LOGIKK\n",
    "# ==========================================\n",
    "def run_full_analysis():\n",
    "    # 1. Oppsett\n",
    "    score_matrix = load_human_similarity_matrix(JSON_PATH)\n",
    "    loader = get_test_loader()\n",
    "    \n",
    "    # 2. Samle data\n",
    "    model_preds, targets = collect_predictions(POSSIBLE_MODELS, loader)\n",
    "    \n",
    "    if not model_preds:\n",
    "        print(\"Ingen modeller ble evaluert. Sjekk filstier.\")\n",
    "        return\n",
    "\n",
    "    # --- 3. BEREGN FAIR COMPARISON MASK (FELLESMENGDE AV FEIL) ---\n",
    "    # Vi finner bildene der ALLE modellene tok feil.\n",
    "    # Dette sikrer at vi sammenligner \"epler med epler\" p√• vanskelige bilder.\n",
    "    n_samples = targets.size(0)\n",
    "    common_failure_mask = torch.ones(n_samples, dtype=torch.bool, device=DEVICE)\n",
    "    \n",
    "    for name, preds in model_preds.items():\n",
    "        incorrect_mask = (preds != targets)\n",
    "        common_failure_mask = common_failure_mask & incorrect_mask\n",
    "        \n",
    "    num_common = common_failure_mask.sum().item()\n",
    "    print(f\"\\nAntall bilder der ALLE {len(model_preds)} modeller tok feil: {num_common}\")\n",
    "    \n",
    "    hard_targets = None\n",
    "    if num_common > 0:\n",
    "        hard_targets = targets[common_failure_mask]\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Ingen felles feil funnet! 'Fair Score' vil v√¶re tom.\")\n",
    "\n",
    "    # --- 4. SAMLE RESULTATER ---\n",
    "    results_list = []\n",
    "\n",
    "    for name, preds in model_preds.items():\n",
    "        # A. Generell Accuracy\n",
    "        acc = (preds == targets).float().mean().item() * 100\n",
    "        \n",
    "        # B. Fair Human Score (Kun p√• felles feil)\n",
    "        fair_score = 0.0\n",
    "        if num_common > 0:\n",
    "            hard_preds = preds[common_failure_mask]\n",
    "            # Hent poeng fra matrisen for disse vanskelige tilfellene\n",
    "            scores = score_matrix[hard_targets, hard_preds]\n",
    "            fair_score = scores.mean().item()\n",
    "            \n",
    "        # Parse navn for plotting (Family vs Epochs)\n",
    "        if \"Probe\" in name:\n",
    "            family = \"Probe\"\n",
    "            epochs = \"Teacher\"\n",
    "        else:\n",
    "            # Eks: \"Baseline (Exp 1) - 300ep\"\n",
    "            parts = name.split(\" - \")\n",
    "            family = parts[0]\n",
    "            epochs = parts[1] if len(parts) > 1 else \"Unknown\"\n",
    "\n",
    "        results_list.append({\n",
    "            \"Full Name\": name,\n",
    "            \"Family\": family,\n",
    "            \"Epochs\": epochs,\n",
    "            \"Accuracy\": acc,\n",
    "            \"Fair Human Score\": fair_score\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(results_list)\n",
    "    \n",
    "    # Sorter etter Fair Human Score (h√∏yest er best)\n",
    "    df_sorted = df.sort_values(by=\"Fair Human Score\", ascending=False)\n",
    "\n",
    "    # --- 5. UTSKRIFT ---\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"RESULTAT: ACCURACY VS FAIR HUMAN SCORE\")\n",
    "    print(\"-\" * 80)\n",
    "    # Vis relevante kolonner\n",
    "    print(df_sorted[[\"Full Name\", \"Accuracy\", \"Fair Human Score\"]].to_string(index=False, float_format=\"%.2f\"))\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Lagre til CSV\n",
    "    df_sorted.to_csv(ARTIFACTS_DIR / \"analysis_full_comparison.csv\", index=False)\n",
    "    print(f\"Data lagret til {ARTIFACTS_DIR / 'analysis_full_comparison.csv'}\")\n",
    "\n",
    "    # --- 6. PLOTTING: ACCURACY VS FAIR HUMAN SCORE ---\n",
    "    if not df.empty and num_common > 0:\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        # Vi bruker Seaborn for √• h√•ndtere farger (Hue) og former (Style) automatisk\n",
    "        sns.scatterplot(\n",
    "            data=df, \n",
    "            x=\"Accuracy\", \n",
    "            y=\"Fair Human Score\", \n",
    "            hue=\"Family\",       # Farge basert p√• modell-familie (Baseline, SBLS, etc.)\n",
    "            style=\"Epochs\",     # Form basert p√• 50ep vs 300ep\n",
    "            s=150,              # St√∏rrelse p√• punkter\n",
    "            alpha=0.9,\n",
    "            palette=\"bright\"\n",
    "        )\n",
    "        \n",
    "        # Annoter Probe spesielt hvis den er med\n",
    "        probe_row = df[df[\"Family\"] == \"Probe\"]\n",
    "        if not probe_row.empty:\n",
    "            plt.text(\n",
    "                probe_row[\"Accuracy\"].values[0], \n",
    "                probe_row[\"Fair Human Score\"].values[0] + 0.01, \n",
    "                \"TEACHER\", \n",
    "                fontweight='bold'\n",
    "            )\n",
    "\n",
    "        plt.title(f\"Trade-off: Accuracy vs Human Alignment\\n(Fair Score based on {num_common} common failures)\", fontsize=14)\n",
    "        plt.xlabel(\"Top-1 Accuracy (%)\", fontsize=12)\n",
    "        plt.ylabel(\"Fair Human Score (Avg on Common Failures)\", fontsize=12)\n",
    "        plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        plot_path = ARTIFACTS_DIR / \"tradeoff_acc_vs_fairscore.png\"\n",
    "        plt.savefig(plot_path, dpi=150)\n",
    "        print(f\"Plot lagret til: {plot_path}\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Kan ikke plotte: Mangler data eller ingen felles feil.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_full_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d30adbc-ee29-49a3-985a-1cc37c275253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# üßπ OPPRYDDING & RESTART üßπ\n",
    "# ==========================================\n",
    "import torch\n",
    "import gc\n",
    "from IPython import get_ipython\n",
    "\n",
    "# 1. Pr√∏v √• slette store objekter manuelt f√∏rst\n",
    "try:\n",
    "    del model, optimizer, scaler, train_loader, test_loader\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "# 2. Kj√∏r Garbage Collection og t√∏m GPU-cache\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# 3. Nuke everything! (Dette sletter ALLE variabler i minnet)\n",
    "# Dette sikrer at neste celle starter med blanke ark.\n",
    "get_ipython().run_line_magic('reset', '-sf')\n",
    "\n",
    "print(\"‚úÖ Minne t√∏mt og variabler nullstilt. Klar for neste eksperiment.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8f1b07-d11c-4839-925f-215ea8c6e433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet18\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ==========================================\n",
    "# 1. KONFIGURASJON\n",
    "# ==========================================\n",
    "DATA_DIR = Path(\"./data\")\n",
    "ARTIFACTS_DIR = Path(\"./artifacts/analysis\")\n",
    "CKPT_DIR = Path(\"./checkpoints\")\n",
    "JSON_PATH = Path(\"human_similarity_ranking.json\")\n",
    "\n",
    "ARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 128\n",
    "NUM_CLASSES = 10\n",
    "CIFAR10_CLASSES = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
    "\n",
    "# ==========================================\n",
    "# DEFINISJON AV ALLE MODELLER\n",
    "# ==========================================\n",
    "# Format: \"Visningsnavn - Epoker\" : \"Filnavn i checkpoints-mappen\"\n",
    "POSSIBLE_MODELS = {\n",
    "    # --- Referanser ---\n",
    "    \"Probe (Teacher)\":                    \"probe_best.pth\",\n",
    "    \n",
    "    # --- Exp 1: Baseline ---\n",
    "    \"Baseline (Exp 1) - 50ep\":            \"02_exp1_baseline_epoch50.pth\",\n",
    "    \"Baseline (Exp 1) - 300ep\":           \"02_exp1_baseline_best.pth\",\n",
    "    \n",
    "    # --- Exp 2: SBLS ---\n",
    "    \"SBLS (Exp 2) - 50ep\":                \"03_exp2_sbls_50ep_best.pth\",\n",
    "    \"SBLS (Exp 2) - 300ep\":               \"03_exp2_sbls_300ep_best.pth\",\n",
    "    \n",
    "    # --- Exp 3: Static Targets ---\n",
    "    \"Static KL (Exp 3a) - 50ep\":          \"04_exp3a_static_probs_50ep_best.pth\",\n",
    "    \"Static KL (Exp 3a) - 300ep\":         \"04_exp3a_static_probs_300ep_best.pth\",\n",
    "    \"Static WMSE (Exp 3b) - 50ep\":        \"05_exp3b_static_logits_50ep_best.pth\",\n",
    "    \"Static WMSE (Exp 3b) - 300ep\":       \"05_exp3b_static_logits_300ep_best.pth\",\n",
    "    \n",
    "    # --- Exp 4: Dynamic Targets ---\n",
    "    \"Dynamic Basic (Exp 4a) - 50ep\":      \"06_exp4a_dynamic_basic_50ep_best.pth\",\n",
    "    \"Dynamic Basic (Exp 4a) - 300ep\":     \"06_exp4a_dynamic_basic_300ep_best.pth\",\n",
    "    \"Dynamic Boost (Exp 4b) - 50ep\":      \"07_exp4b_dynamic_boost_50ep_best.pth\",\n",
    "    \"Dynamic Boost (Exp 4b) - 300ep\":     \"07_exp4b_dynamic_boost_300ep_best.pth\",\n",
    "    \n",
    "    # --- Exp 5a: Capped (Alle caps) ---\n",
    "    \"Capped 0.6 (Exp 5a) - 50ep\":         \"08_exp5a_capped_run_50ep_cap0.6_best.pth\",\n",
    "    \"Capped 0.6 (Exp 5a) - 300ep\":        \"08_exp5a_capped_run_300ep_cap0.6_best.pth\",\n",
    "    \n",
    "    \"Capped 0.8 (Exp 5a) - 50ep\":         \"08_exp5a_capped_run_50ep_cap0.8_best.pth\",\n",
    "    \"Capped 0.8 (Exp 5a) - 300ep\":        \"08_exp5a_capped_run_300ep_cap0.8_best.pth\",\n",
    "    \n",
    "    \"Capped 0.95 (Exp 5a) - 50ep\":        \"08_exp5a_capped_run_50ep_cap0.95_best.pth\",\n",
    "    \"Capped 0.95 (Exp 5a) - 300ep\":       \"08_exp5a_capped_run_300ep_cap0.95_best.pth\",\n",
    "    \n",
    "    # --- Exp 5b: Capped + Swap (Alle caps) ---\n",
    "    \"Swap 0.6 (Exp 5b) - 50ep\":           \"09_exp5b_capped_swap_run_50ep_cap0.6_best.pth\",\n",
    "    \"Swap 0.6 (Exp 5b) - 300ep\":          \"09_exp5b_capped_swap_run_300ep_cap0.6_best.pth\",\n",
    "    \n",
    "    \"Swap 0.8 (Exp 5b) - 50ep\":           \"09_exp5b_capped_swap_run_50ep_cap0.8_best.pth\",\n",
    "    \"Swap 0.8 (Exp 5b) - 300ep\":          \"09_exp5b_capped_swap_run_300ep_cap0.8_best.pth\",\n",
    "    \n",
    "    \"Swap 0.95 (Exp 5b) - 50ep\":          \"09_exp5b_capped_swap_run_50ep_cap0.95_best.pth\",\n",
    "    \"Swap 0.95 (Exp 5b) - 300ep\":         \"09_exp5b_capped_swap_run_300ep_cap0.95_best.pth\"\n",
    "}\n",
    "\n",
    "# ==========================================\n",
    "# 2. DATA & MODELL DEFINISJONER\n",
    "# ==========================================\n",
    "def make_cifar_resnet18(num_classes=10):\n",
    "    m = resnet18(weights=None)\n",
    "    m.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    m.maxpool = nn.Identity()\n",
    "    m.fc = nn.Linear(m.fc.in_features, num_classes)\n",
    "    return m\n",
    "\n",
    "def get_test_loader():\n",
    "    test_tf = T.Compose([\n",
    "        T.ToTensor(),\n",
    "        T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "    test_ds = torchvision.datasets.CIFAR10(root=DATA_DIR, train=False, download=True, transform=test_tf)\n",
    "    # Shuffle=False er KRITISK for \"Fair Comparison\" (indeks-matching)\n",
    "    return DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "# ==========================================\n",
    "# 3. HUMAN SIMILARITY MATRIX LOADER\n",
    "# ==========================================\n",
    "def load_human_similarity_matrix(json_path):\n",
    "    if not json_path.exists():\n",
    "        print(f\"‚ö†Ô∏è  ADVARSEL: Fant ikke {json_path}. Lager dummy-matrise (0 poeng).\")\n",
    "        return torch.zeros((NUM_CLASSES, NUM_CLASSES), device=DEVICE)\n",
    "    \n",
    "    with open(json_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    wins_data = data.get(\"wins\", {})\n",
    "    score_matrix = torch.zeros((NUM_CLASSES, NUM_CLASSES), device=DEVICE)\n",
    "    \n",
    "    for true_idx, true_name in enumerate(CIFAR10_CLASSES):\n",
    "        if true_name not in wins_data: continue\n",
    "        for pred_idx, pred_name in enumerate(CIFAR10_CLASSES):\n",
    "            if true_idx == pred_idx: continue # Ignorer diagonalen (korrekt svar)\n",
    "            \n",
    "            # Hent poeng\n",
    "            points = wins_data[true_name].get(pred_name, 0)\n",
    "            score_matrix[true_idx, pred_idx] = points\n",
    "\n",
    "    print(f\"Human Similarity Matrix lastet fra {json_path}.\")\n",
    "    return score_matrix\n",
    "\n",
    "# ==========================================\n",
    "# 4. PREDICTION COLLECTOR\n",
    "# ==========================================\n",
    "def collect_predictions(models_dict, loader):\n",
    "    all_preds = {}\n",
    "    targets = []\n",
    "    \n",
    "    # Hent targets f√∏rst\n",
    "    print(\"Laster testdata (fasit)...\")\n",
    "    for _, y in loader:\n",
    "        targets.append(y.to(DEVICE))\n",
    "    targets = torch.cat(targets)\n",
    "    \n",
    "    # Iterer over modeller\n",
    "    print(\"\\nStarter inferens p√• alle modeller...\")\n",
    "    for name, filename in tqdm(models_dict.items(), desc=\"Modeller\"):\n",
    "        ckpt_path = CKPT_DIR / filename\n",
    "        \n",
    "        if not ckpt_path.exists():\n",
    "            # Fallback hvis stien er litt annerledes eller bruker la inn full path\n",
    "            if Path(filename).exists():\n",
    "                ckpt_path = Path(filename)\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è  Hopper over {name}: Fant ikke {ckpt_path}\")\n",
    "                continue\n",
    "        \n",
    "        # Last modell\n",
    "        model = make_cifar_resnet18(NUM_CLASSES).to(DEVICE)\n",
    "        try:\n",
    "            model.load_state_dict(torch.load(ckpt_path, map_location=DEVICE))\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Kunne ikke laste {name}: {e}\")\n",
    "            continue\n",
    "            \n",
    "        model.eval()\n",
    "        preds_list = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for x, _ in loader:\n",
    "                x = x.to(DEVICE)\n",
    "                logits = model(x)\n",
    "                preds_list.append(logits.argmax(dim=1))\n",
    "        \n",
    "        all_preds[name] = torch.cat(preds_list)\n",
    "        \n",
    "    return all_preds, targets\n",
    "\n",
    "# ==========================================\n",
    "# 5. ANALYSE-LOGIKK\n",
    "# ==========================================\n",
    "def run_full_analysis():\n",
    "    # 1. Oppsett\n",
    "    score_matrix = load_human_similarity_matrix(JSON_PATH)\n",
    "    loader = get_test_loader()\n",
    "    \n",
    "    # 2. Samle data\n",
    "    model_preds, targets = collect_predictions(POSSIBLE_MODELS, loader)\n",
    "    \n",
    "    if not model_preds:\n",
    "        print(\"Ingen modeller ble evaluert. Sjekk filstier.\")\n",
    "        return\n",
    "\n",
    "    # --- 3. BEREGN FAIR COMPARISON MASK (FELLESMENGDE AV FEIL) ---\n",
    "    # Vi finner bildene der ALLE modellene tok feil.\n",
    "    n_samples = targets.size(0)\n",
    "    common_failure_mask = torch.ones(n_samples, dtype=torch.bool, device=DEVICE)\n",
    "    \n",
    "    for name, preds in model_preds.items():\n",
    "        incorrect_mask = (preds != targets)\n",
    "        common_failure_mask = common_failure_mask & incorrect_mask\n",
    "        \n",
    "    num_common = common_failure_mask.sum().item()\n",
    "    print(f\"\\nAntall bilder der ALLE {len(model_preds)} modeller tok feil: {num_common}\")\n",
    "    \n",
    "    hard_targets = None\n",
    "    if num_common > 0:\n",
    "        hard_targets = targets[common_failure_mask]\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Ingen felles feil funnet! 'Fair Score' vil v√¶re tom.\")\n",
    "\n",
    "    # --- 4. SAMLE RESULTATER ---\n",
    "    results_list = []\n",
    "\n",
    "    for name, preds in model_preds.items():\n",
    "        # A. Generell Accuracy\n",
    "        acc = (preds == targets).float().mean().item() * 100\n",
    "        \n",
    "        # B. Fair Human Score (Kun p√• felles feil)\n",
    "        fair_score = 0.0\n",
    "        if num_common > 0:\n",
    "            hard_preds = preds[common_failure_mask]\n",
    "            # Hent poeng fra matrisen for disse vanskelige tilfellene\n",
    "            scores = score_matrix[hard_targets, hard_preds]\n",
    "            fair_score = scores.mean().item()\n",
    "            \n",
    "        # Parse navn for plotting (Family vs Epochs)\n",
    "        # Eks: \"Capped 0.8 (Exp 5a) - 300ep\"\n",
    "        if \"Probe\" in name:\n",
    "            family = \"Probe\"\n",
    "            epochs = \"Teacher\"\n",
    "        else:\n",
    "            parts = name.split(\" - \")\n",
    "            family = parts[0]\n",
    "            epochs = parts[1] if len(parts) > 1 else \"Unknown\"\n",
    "\n",
    "        results_list.append({\n",
    "            \"Full Name\": name,\n",
    "            \"Family\": family,\n",
    "            \"Epochs\": epochs,\n",
    "            \"Accuracy\": acc,\n",
    "            \"Fair Human Score\": fair_score\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(results_list)\n",
    "    \n",
    "    # Sorter etter Fair Human Score (h√∏yest er best)\n",
    "    df_sorted = df.sort_values(by=\"Fair Human Score\", ascending=False)\n",
    "\n",
    "    # --- 5. UTSKRIFT ---\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"RESULTAT: ACCURACY VS FAIR HUMAN SCORE\")\n",
    "    print(f\"Basert p√• {num_common} vanskelige bilder som ingen modeller klarte.\")\n",
    "    print(\"-\" * 80)\n",
    "    print(df_sorted[[\"Full Name\", \"Accuracy\", \"Fair Human Score\"]].to_string(index=False, float_format=\"%.2f\"))\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Lagre til CSV\n",
    "    df_sorted.to_csv(ARTIFACTS_DIR / \"analysis_full_comparison.csv\", index=False)\n",
    "    print(f\"Data lagret til {ARTIFACTS_DIR / 'analysis_full_comparison.csv'}\")\n",
    "\n",
    "    # --- 6. PLOTTING: ACCURACY VS FAIR HUMAN SCORE ---\n",
    "    if not df.empty and num_common > 0:\n",
    "        plt.figure(figsize=(14, 10)) # St√∏rre figur for √• f√• plass til alt\n",
    "        \n",
    "        sns.scatterplot(\n",
    "            data=df, \n",
    "            x=\"Accuracy\", \n",
    "            y=\"Fair Human Score\", \n",
    "            hue=\"Family\",       # Farge = Modelltype\n",
    "            style=\"Epochs\",     # Form = 50ep vs 300ep\n",
    "            s=200,              # St√∏rre punkter\n",
    "            alpha=0.8,\n",
    "            palette=\"tab20\"     # Fargepalett med mange farger\n",
    "        )\n",
    "        \n",
    "        # Annoter Probe\n",
    "        probe_row = df[df[\"Family\"] == \"Probe\"]\n",
    "        if not probe_row.empty:\n",
    "            plt.text(\n",
    "                probe_row[\"Accuracy\"].values[0], \n",
    "                probe_row[\"Fair Human Score\"].values[0] + 0.01, \n",
    "                \"TEACHER\", \n",
    "                fontweight='bold',\n",
    "                color='black'\n",
    "            )\n",
    "\n",
    "        plt.title(f\"Trade-off: Accuracy vs Human Alignment\\n(Fair Score based on {num_common} common failures)\", fontsize=16)\n",
    "        plt.xlabel(\"Top-1 Accuracy (%)\", fontsize=14)\n",
    "        plt.ylabel(\"Fair Human Score (Avg on Common Failures)\", fontsize=14)\n",
    "        plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "        \n",
    "        # Flytt legenden ut av plottet\n",
    "        plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0., title=\"Models\")\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        plot_path = ARTIFACTS_DIR / \"tradeoff_acc_vs_fairscore_ALL.png\"\n",
    "        plt.savefig(plot_path, dpi=150)\n",
    "        print(f\"Plot lagret til: {plot_path}\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Kan ikke plotte: Mangler data eller ingen felles feil.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_full_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58333605-3f75-4e7b-a103-e701b04de50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# üßπ OPPRYDDING & RESTART üßπ\n",
    "# ==========================================\n",
    "import torch\n",
    "import gc\n",
    "from IPython import get_ipython\n",
    "\n",
    "# 1. Pr√∏v √• slette store objekter manuelt f√∏rst\n",
    "try:\n",
    "    del model, optimizer, scaler, train_loader, test_loader\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "# 2. Kj√∏r Garbage Collection og t√∏m GPU-cache\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# 3. Nuke everything! (Dette sletter ALLE variabler i minnet)\n",
    "# Dette sikrer at neste celle starter med blanke ark.\n",
    "get_ipython().run_line_magic('reset', '-sf')\n",
    "\n",
    "print(\"‚úÖ Minne t√∏mt og variabler nullstilt. Klar for neste eksperiment.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4bdfa6-591a-41cb-97de-db615bba56f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet18\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ==========================================\n",
    "# 1. KONFIGURASJON\n",
    "# ==========================================\n",
    "DATA_DIR = Path(\"./data\")\n",
    "# Ny mappe for dette eksperimentet (9 poeng)\n",
    "ARTIFACTS_DIR = Path(\"./artifacts/human_weighted_accuracy_9p\")\n",
    "CKPT_DIR = Path(\"./checkpoints\")\n",
    "JSON_PATH = Path(\"human_similarity_ranking.json\")\n",
    "\n",
    "ARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 128\n",
    "NUM_CLASSES = 10\n",
    "CIFAR10_CLASSES = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
    "\n",
    "# ==========================================\n",
    "# 2. DEFINISJON AV ALLE MODELLER\n",
    "# ==========================================\n",
    "POSSIBLE_MODELS = {\n",
    "    # --- Referanser ---\n",
    "    \"Probe (Teacher)\":                    \"probe_best.pth\",\n",
    "    \n",
    "    # --- Exp 1: Baseline ---\n",
    "    \"Baseline (Exp 1) - 50ep\":            \"02_exp1_baseline_epoch50.pth\",\n",
    "    \"Baseline (Exp 1) - 300ep\":           \"02_exp1_baseline_best.pth\",\n",
    "    \n",
    "    # --- Exp 2: SBLS ---\n",
    "    \"SBLS (Exp 2) - 50ep\":                \"03_exp2_sbls_50ep_best.pth\",\n",
    "    \"SBLS (Exp 2) - 300ep\":               \"03_exp2_sbls_300ep_best.pth\",\n",
    "    \n",
    "    # --- Exp 3: Static Targets ---\n",
    "    \"Static KL (Exp 3a) - 50ep\":          \"04_exp3a_static_probs_50ep_best.pth\",\n",
    "    \"Static KL (Exp 3a) - 300ep\":         \"04_exp3a_static_probs_300ep_best.pth\",\n",
    "    \"Static WMSE (Exp 3b) - 50ep\":        \"05_exp3b_static_logits_50ep_best.pth\",\n",
    "    \"Static WMSE (Exp 3b) - 300ep\":       \"05_exp3b_static_logits_300ep_best.pth\",\n",
    "    \n",
    "    # --- Exp 4: Dynamic Targets ---\n",
    "    \"Dynamic Basic (Exp 4a) - 50ep\":      \"06_exp4a_dynamic_basic_50ep_best.pth\",\n",
    "    \"Dynamic Basic (Exp 4a) - 300ep\":     \"06_exp4a_dynamic_basic_300ep_best.pth\",\n",
    "    \"Dynamic Boost (Exp 4b) - 50ep\":      \"07_exp4b_dynamic_boost_50ep_best.pth\",\n",
    "    \"Dynamic Boost (Exp 4b) - 300ep\":     \"07_exp4b_dynamic_boost_300ep_best.pth\",\n",
    "    \n",
    "    # --- Exp 5a: Capped (Alle caps) ---\n",
    "    \"Capped 0.6 (Exp 5a) - 50ep\":         \"08_exp5a_capped_run_50ep_cap0.6_best.pth\",\n",
    "    \"Capped 0.6 (Exp 5a) - 300ep\":        \"08_exp5a_capped_run_300ep_cap0.6_best.pth\",\n",
    "    \n",
    "    \"Capped 0.8 (Exp 5a) - 50ep\":         \"08_exp5a_capped_run_50ep_cap0.8_best.pth\",\n",
    "    \"Capped 0.8 (Exp 5a) - 300ep\":        \"08_exp5a_capped_run_300ep_cap0.8_best.pth\",\n",
    "    \n",
    "    \"Capped 0.95 (Exp 5a) - 50ep\":        \"08_exp5a_capped_run_50ep_cap0.95_best.pth\",\n",
    "    \"Capped 0.95 (Exp 5a) - 300ep\":       \"08_exp5a_capped_run_300ep_cap0.95_best.pth\",\n",
    "    \n",
    "    # --- Exp 5b: Capped + Swap (Alle caps) ---\n",
    "    \"Swap 0.6 (Exp 5b) - 50ep\":           \"09_exp5b_capped_swap_run_50ep_cap0.6_best.pth\",\n",
    "    \"Swap 0.6 (Exp 5b) - 300ep\":          \"09_exp5b_capped_swap_run_300ep_cap0.6_best.pth\",\n",
    "    \n",
    "    \"Swap 0.8 (Exp 5b) - 50ep\":           \"09_exp5b_capped_swap_run_50ep_cap0.8_best.pth\",\n",
    "    \"Swap 0.8 (Exp 5b) - 300ep\":          \"09_exp5b_capped_swap_run_300ep_cap0.8_best.pth\",\n",
    "    \n",
    "    \"Swap 0.95 (Exp 5b) - 50ep\":          \"09_exp5b_capped_swap_run_50ep_cap0.95_best.pth\",\n",
    "    \"Swap 0.95 (Exp 5b) - 300ep\":         \"09_exp5b_capped_swap_run_300ep_cap0.95_best.pth\"\n",
    "}\n",
    "\n",
    "# ==========================================\n",
    "# 3. OPPSETT AV DATA & MODELL\n",
    "# ==========================================\n",
    "def make_cifar_resnet18(num_classes=10):\n",
    "    m = resnet18(weights=None)\n",
    "    m.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    m.maxpool = nn.Identity()\n",
    "    m.fc = nn.Linear(m.fc.in_features, num_classes)\n",
    "    return m\n",
    "\n",
    "def get_test_loader():\n",
    "    test_tf = T.Compose([\n",
    "        T.ToTensor(),\n",
    "        T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "    test_ds = torchvision.datasets.CIFAR10(root=DATA_DIR, train=False, download=True, transform=test_tf)\n",
    "    return DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "# ==========================================\n",
    "# 4. LASTE SCORINGSMATRISE (MED 9 POENG FOR RETT SVAR)\n",
    "# ==========================================\n",
    "def load_weighted_score_matrix(json_path):\n",
    "    \"\"\"\n",
    "    Laster human_similarity_ranking.json.\n",
    "    - Diagonalen (Rett svar) settes til 9.0 poeng.\n",
    "    - Feil svar f√•r poeng fra JSON-filen (0-10, men i praksis lavere).\n",
    "    \"\"\"\n",
    "    # Start med nuller\n",
    "    score_matrix = torch.zeros((NUM_CLASSES, NUM_CLASSES), device=DEVICE)\n",
    "    \n",
    "    # 1. Sett diagonalen til 9 (Ny Max score for rett svar)\n",
    "    for i in range(NUM_CLASSES):\n",
    "        score_matrix[i, i] = 9.0  # <--- ENDRING HER\n",
    "    \n",
    "    # 2. Fyll inn poeng for feil svar fra JSON\n",
    "    if not json_path.exists():\n",
    "        print(f\"‚ö†Ô∏è  ADVARSEL: Fant ikke {json_path}. Bruker kun diagonal (Acc).\")\n",
    "        return score_matrix\n",
    "\n",
    "    with open(json_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    wins_data = data.get(\"wins\", {})\n",
    "    \n",
    "    for true_idx, true_name in enumerate(CIFAR10_CLASSES):\n",
    "        if true_name not in wins_data: continue\n",
    "        for pred_idx, pred_name in enumerate(CIFAR10_CLASSES):\n",
    "            if true_idx == pred_idx: continue # Allerede satt til 9\n",
    "            \n",
    "            # Hent poeng for feilen\n",
    "            points = wins_data[true_name].get(pred_name, 0)\n",
    "            score_matrix[true_idx, pred_idx] = points\n",
    "\n",
    "    print(f\"‚úÖ Weighted Score Matrix lastet. Rett svar = 9p, Feil svar = JSON poeng.\")\n",
    "    return score_matrix\n",
    "\n",
    "# ==========================================\n",
    "# 5. EVALUERINGSL√òKKE\n",
    "# ==========================================\n",
    "def evaluate_models(models_dict, loader, score_matrix):\n",
    "    results = []\n",
    "    \n",
    "    print(f\"\\nStarter evaluering av {len(models_dict)} modeller...\")\n",
    "    print(\"Metrikk: Total Weighted Score (Avg per bilde, Max=9)\")\n",
    "    \n",
    "    # Hent targets (fasit) en gang for alle\n",
    "    all_targets = []\n",
    "    for _, y in loader:\n",
    "        all_targets.append(y.to(DEVICE))\n",
    "    all_targets = torch.cat(all_targets)\n",
    "    \n",
    "    for name, filename in tqdm(models_dict.items(), desc=\"Evaluerer\"):\n",
    "        ckpt_path = CKPT_DIR / filename\n",
    "        \n",
    "        # Sjekk om fil finnes\n",
    "        if not ckpt_path.exists():\n",
    "            if Path(filename).exists(): ckpt_path = Path(filename)\n",
    "            else: continue\n",
    "            \n",
    "        # Last modell\n",
    "        model = make_cifar_resnet18(NUM_CLASSES).to(DEVICE)\n",
    "        try:\n",
    "            model.load_state_dict(torch.load(ckpt_path, map_location=DEVICE))\n",
    "        except Exception:\n",
    "            continue\n",
    "            \n",
    "        model.eval()\n",
    "        all_preds = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for x, _ in loader:\n",
    "                x = x.to(DEVICE)\n",
    "                logits = model(x)\n",
    "                all_preds.append(logits.argmax(dim=1))\n",
    "        \n",
    "        all_preds = torch.cat(all_preds)\n",
    "        \n",
    "        # --- BEREGN SCORE ---\n",
    "        # score_matrix[true_class, pred_class] gir poengene for hvert bilde\n",
    "        scores = score_matrix[all_targets, all_preds]\n",
    "        \n",
    "        # Gjennomsnittlig score (Weighted Accuracy)\n",
    "        avg_score = scores.mean().item()\n",
    "        \n",
    "        # Standard Accuracy (for referanse)\n",
    "        acc = (all_preds == all_targets).float().mean().item() * 100\n",
    "        \n",
    "        # Parse navn for gruppering\n",
    "        if \"Probe\" in name:\n",
    "            family = \"Probe\"\n",
    "            epochs = \"Teacher\"\n",
    "        else:\n",
    "            parts = name.split(\" - \")\n",
    "            family = parts[0]\n",
    "            epochs = parts[1] if len(parts) > 1 else \"Unknown\"\n",
    "            \n",
    "        results.append({\n",
    "            \"Full Name\": name,\n",
    "            \"Family\": family,\n",
    "            \"Epochs\": epochs,\n",
    "            \"Standard Accuracy (%)\": acc,\n",
    "            \"Weighted Human Score (Max 9)\": avg_score\n",
    "        })\n",
    "        \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# ==========================================\n",
    "# 6. PLOTTING OG LAGRING\n",
    "# ==========================================\n",
    "def run_weighted_analysis():\n",
    "    # Last data\n",
    "    score_matrix = load_weighted_score_matrix(JSON_PATH)\n",
    "    loader = get_test_loader()\n",
    "    \n",
    "    # Evaluer\n",
    "    df = evaluate_models(POSSIBLE_MODELS, loader, score_matrix)\n",
    "    \n",
    "    if df.empty:\n",
    "        print(\"Ingen resultater √• vise.\")\n",
    "        return\n",
    "\n",
    "    # Sorter\n",
    "    df = df.sort_values(by=\"Weighted Human Score (Max 9)\", ascending=False)\n",
    "    \n",
    "    # Lagre CSV\n",
    "    csv_path = ARTIFACTS_DIR / \"weighted_human_accuracy_9p.csv\"\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"\\nResultater lagret til: {csv_path}\")\n",
    "    \n",
    "    # Print tabell\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"RESULTAT: WEIGHTED HUMAN ACCURACY (Rett=9p, Feil=Likhetspoeng)\")\n",
    "    print(\"-\" * 80)\n",
    "    print(df[[\"Full Name\", \"Standard Accuracy (%)\", \"Weighted Human Score (Max 9)\"]].to_string(index=False, float_format=\"%.3f\"))\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # --- PLOT 1: GROUPED BAR CHART (Epoch Comparison) ---\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    # Filtrer vekk Probe for dette plottet for √• sammenligne treningsmetoder renere\n",
    "    plot_df = df[df[\"Family\"] != \"Probe\"]\n",
    "    \n",
    "    sns.barplot(\n",
    "        data=plot_df,\n",
    "        x=\"Family\",\n",
    "        y=\"Weighted Human Score (Max 9)\",\n",
    "        hue=\"Epochs\",\n",
    "        palette=\"viridis\",\n",
    "        edgecolor=\"black\"\n",
    "    )\n",
    "    \n",
    "    # Legg til linje for Probe (Teacher) Score hvis den finnes\n",
    "    probe_row = df[df[\"Family\"] == \"Probe\"]\n",
    "    if not probe_row.empty:\n",
    "        probe_score = probe_row[\"Weighted Human Score (Max 9)\"].values[0]\n",
    "        plt.axhline(y=probe_score, color='red', linestyle='--', label=f'Teacher Score ({probe_score:.2f})')\n",
    "    \n",
    "    plt.title(\"Weighted Human Accuracy (Correct=9p)\", fontsize=16)\n",
    "    plt.ylabel(\"Average Weighted Score (Max 9)\", fontsize=14)\n",
    "    plt.xlabel(\"Model Variant\", fontsize=14)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.legend(title=\"Training Epochs\")\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    # Juster Y-akse for √• zoome inn p√• toppen (men med tak p√• 9.1)\n",
    "    min_score = df[\"Weighted Human Score (Max 9)\"].min()\n",
    "    plt.ylim(bottom=min_score - 0.5, top=9.1) \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plot_path_bar = ARTIFACTS_DIR / \"weighted_score_comparison_bar.png\"\n",
    "    plt.savefig(plot_path_bar, dpi=150)\n",
    "    print(f\"Barplot lagret til: {plot_path_bar}\")\n",
    "    plt.show()\n",
    "\n",
    "    # --- PLOT 2: SCATTER (Acc vs Weighted Score) ---\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.scatterplot(\n",
    "        data=df,\n",
    "        x=\"Standard Accuracy (%)\",\n",
    "        y=\"Weighted Human Score (Max 9)\",\n",
    "        hue=\"Family\",\n",
    "        style=\"Epochs\",\n",
    "        s=150,\n",
    "        palette=\"tab20\",\n",
    "        alpha=0.9\n",
    "    )\n",
    "    \n",
    "    plt.title(\"Correlation: Standard Accuracy vs Weighted Score (Correct=9p)\", fontsize=16)\n",
    "    plt.ylabel(\"Weighted Human Score (Max 9)\", fontsize=12)\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "    plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0.)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plot_path_scatter = ARTIFACTS_DIR / \"acc_vs_weighted_score_scatter.png\"\n",
    "    plt.savefig(plot_path_scatter, dpi=150)\n",
    "    print(f\"Scatterplot lagret til: {plot_path_scatter}\")\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_weighted_analysis()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
