{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22ed4ad-c50c-4bc2-9d4a-536f3114084a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 1 (Imports) ===\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models import resnet18\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# === CELL 2 (Configuration) ===\n",
    "# --- Konfigurasjon ---\n",
    "EXPERIMENT_NAME = \"01_probe_baseline\"\n",
    "DATA_DIR = Path(\"./data\")\n",
    "ARTIFACTS_DIR = Path(f\"./artifacts/{EXPERIMENT_NAME}\")\n",
    "CKPT_DIR = Path(\"./checkpoints\")\n",
    "\n",
    "# Opprett mapper\n",
    "ARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CKPT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Hyperparametere\n",
    "# Vi bruker 50 epoker for å sikre en veldig sterk \"Lærer\" (Probe).\n",
    "# Dette tilsvarer den \"sterke sonden\" (v2) fra det gamle repoet.\n",
    "EPOCHS = 50 \n",
    "BATCH_SIZE = 128\n",
    "LR = 1e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "SEED = 42\n",
    "NUM_WORKERS = 2\n",
    "USE_AMP = True\n",
    "\n",
    "# Data & Klasser\n",
    "NUM_CLASSES = 10\n",
    "CIFAR10_CLASSES = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
    "\n",
    "print(f\"Konfigurasjon satt. Artefakter lagres til: {ARTIFACTS_DIR}\")\n",
    "\n",
    "# === CELL 3 (Reproducibility) ===\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "set_seed(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Kjører på: {device}\")\n",
    "\n",
    "# === CELL 4 (Data Loading) ===\n",
    "# Samme transformasjoner som originalt repo\n",
    "train_tf = T.Compose([\n",
    "    T.RandomCrop(32, padding=4),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# Eval transform (ingen augmentering) for validering OG ekstraksjon av targets\n",
    "eval_tf = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# Datasets\n",
    "train_ds = torchvision.datasets.CIFAR10(root=DATA_DIR, train=True, download=True, transform=train_tf)\n",
    "# Vi trenger treningssettet uten augmentering for å hente ut \"sannheten\" modellen har lært\n",
    "train_ds_eval = torchvision.datasets.CIFAR10(root=DATA_DIR, train=True, download=True, transform=eval_tf)\n",
    "test_ds = torchvision.datasets.CIFAR10(root=DATA_DIR, train=False, download=True, transform=eval_tf)\n",
    "\n",
    "# Loaders\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "train_eval_loader = DataLoader(train_ds_eval, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "print(f\"Data lastet. Train size: {len(train_ds)}, Test size: {len(test_ds)}\")\n",
    "\n",
    "# === CELL 5 (Model Definition) ===\n",
    "def make_cifar_resnet18(num_classes=10):\n",
    "    \"\"\"\n",
    "    Standard ResNet18 tilpasset CIFAR-10 (slik som i originalt repo).\n",
    "    Fjerner maxpool og endrer første conv til 3x3 kernel.\n",
    "    \"\"\"\n",
    "    m = resnet18(weights=None)\n",
    "    m.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    m.maxpool = nn.Identity()\n",
    "    m.fc = nn.Linear(m.fc.in_features, num_classes)\n",
    "    return m\n",
    "\n",
    "model = make_cifar_resnet18(NUM_CLASSES).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=USE_AMP)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# === CELL 6 (Training & Eval Functions) ===\n",
    "def train_one_epoch(model, loader, optimizer, scaler):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    \n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        \n",
    "        with torch.autocast(device_type=\"cuda\" if device.type == \"cuda\" else \"cpu\", enabled=USE_AMP):\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        total_loss += loss.item() * x.size(0)\n",
    "        correct += (logits.argmax(dim=1) == y).sum().item()\n",
    "        total += x.size(0)\n",
    "        \n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "        logits = model(x)\n",
    "        correct += (logits.argmax(dim=1) == y).sum().item()\n",
    "        total += x.size(0)\n",
    "    return correct / total\n",
    "\n",
    "# === CELL 7 (Main Training Loop) ===\n",
    "print(f\"Starter trening av Probe i {EPOCHS} epoker...\")\n",
    "best_acc = 0.0\n",
    "stats = {\"train_loss\": [], \"train_acc\": [], \"test_acc\": []}\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    t_loss, t_acc = train_one_epoch(model, train_loader, optimizer, scaler)\n",
    "    val_acc = evaluate(model, test_loader)\n",
    "    \n",
    "    stats[\"train_loss\"].append(t_loss)\n",
    "    stats[\"train_acc\"].append(t_acc)\n",
    "    stats[\"test_acc\"].append(val_acc)\n",
    "    \n",
    "    # Lagre beste modell\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), CKPT_DIR / \"probe_best.pth\")\n",
    "        \n",
    "    print(f\"Epoke {epoch:02d} | Loss: {t_loss:.4f} | Train Acc: {t_acc:.4f} | Test Acc: {val_acc:.4f}\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Ferdig! Beste Test Acc: {best_acc:.4f}. Tid: {total_time/60:.1f} min.\")\n",
    "\n",
    "# Lagre slutt-statistikk\n",
    "with open(ARTIFACTS_DIR / \"training_stats.json\", \"w\") as f:\n",
    "    json.dump(stats, f, indent=2)\n",
    "\n",
    "# === CELL 8 (Extract Stats / Targets) ===\n",
    "# Her genererer vi \"Sannheten\" som de andre eksperimentene skal bruke.\n",
    "# Vi gjør det nøyaktig som i originalt repo:\n",
    "# - avg_probs: Gjennomsnitt av softmax (for Exp 3a)\n",
    "# - avg_logits: Gjennomsnitt av rå logits (for Exp 3b, 4, 5)\n",
    "\n",
    "print(\"Laster beste modell for å generere targets...\")\n",
    "model.load_state_dict(torch.load(CKPT_DIR / \"probe_best.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "sum_probs = torch.zeros(NUM_CLASSES, NUM_CLASSES, dtype=torch.float64, device=device)\n",
    "sum_logits = torch.zeros(NUM_CLASSES, NUM_CLASSES, dtype=torch.float64, device=device)\n",
    "counts = torch.zeros(NUM_CLASSES, dtype=torch.long, device=device)\n",
    "\n",
    "print(\"Analyserer treningssettet (eval-modus)...\")\n",
    "with torch.no_grad():\n",
    "    for x, y in train_eval_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        logits = model(x)\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        \n",
    "        # Akkumuler per klasse\n",
    "        for c in range(NUM_CLASSES):\n",
    "            mask = (y == c)\n",
    "            if mask.any():\n",
    "                # sum_probs: brukes av Exp 3a (KL Div)\n",
    "                sum_probs[c] += probs[mask].sum(dim=0)\n",
    "                # sum_logits: brukes av Exp 3b, 4, 5 (WMSE)\n",
    "                sum_logits[c] += logits[mask].sum(dim=0)\n",
    "                counts[c] += mask.sum()\n",
    "\n",
    "# Beregn gjennomsnitt\n",
    "avg_probs = (sum_probs / counts.view(-1, 1).clamp_min(1)).float().cpu()\n",
    "avg_logits = (sum_logits / counts.view(-1, 1).clamp_min(1)).float().cpu()\n",
    "\n",
    "# Lagre filene\n",
    "targets_path = ARTIFACTS_DIR / \"probe_targets.pt\"\n",
    "torch.save({\n",
    "    \"class_avg_probs\": avg_probs,\n",
    "    \"class_avg_logits\": avg_logits,\n",
    "    \"counts\": counts.cpu(),\n",
    "    \"classes\": CIFAR10_CLASSES\n",
    "}, targets_path)\n",
    "\n",
    "print(f\"Targets (både logits og probs) lagret til: {targets_path}\")\n",
    "\n",
    "# === CELL 9 (Visualization) ===\n",
    "# Generer heatmap av sannsynlighetsfordelingen (Final Target Distribution)\n",
    "# Dette viser hva Læreren mener hver klasse \"ligner på\".\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(\n",
    "    avg_probs.numpy(),\n",
    "    xticklabels=CIFAR10_CLASSES,\n",
    "    yticklabels=CIFAR10_CLASSES,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cmap=\"viridis\",\n",
    "    cbar_kws={'label': 'Teacher Confidence (Softmax Avg)'}\n",
    ")\n",
    "plt.title(f\"Probe Learned Distribution (Acc: {best_acc:.2%})\")\n",
    "plt.xlabel(\"Predicted Class\")\n",
    "plt.ylabel(\"True Class\")\n",
    "plt.tight_layout()\n",
    "\n",
    "heatmap_path = ARTIFACTS_DIR / \"probe_distribution_heatmap.png\"\n",
    "plt.savefig(heatmap_path)\n",
    "print(f\"Heatmap lagret til: {heatmap_path}\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
